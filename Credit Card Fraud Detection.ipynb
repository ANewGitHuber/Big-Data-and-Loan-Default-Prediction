{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0e0dc808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# handle dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import warnings\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Data set from https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2915229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train test dataset \n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "66b3145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y variables as dataframe \n",
    "y = df['Class']\n",
    "X = df.iloc[:, df.columns != 'Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d2d7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# solve error by downgrading to install scikit-learn==1.2.2 \n",
    "# ''' steps : \n",
    "# 1. install pip \n",
    "# 2. uninstall sci-kit \n",
    "# 3. uninstall imblearn\n",
    "# 4. install sci-kit 1.2.2 \n",
    "# 5. install imblearn \n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a528c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over sample using SMOTE\n",
    "# -- by inspecting the data, we see that the minority class is extremely class (fraud \"Class\" == 1)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f27f4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Code to Inspect the data set -- \n",
    "# df_oversampled = X_res\n",
    "# df_oversampled['Outcome_Variable'] = y_res\n",
    "# df_oversampled\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# df_oversampled['Outcome_Variable'].value_counts().plot(kind='bar', ax=ax, fontsize=14)\n",
    "# ax.set_title('Oversampled Dataset', fontsize=16)\n",
    "# ax.set_ylabel('Observation counts', fontsize=14)\n",
    "# ax.set_xlabel('Class', fontsize=14)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5d5baf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up K-Fold Cross Validation \n",
    "n_splits = 5\n",
    "shuffle = True\n",
    "random_state = 809\n",
    "cv = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "# plot = plot_cv_indices(cv, X_res, y_res, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "abb0ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, n_splits, lw=10):\n",
    "    '''\n",
    "    This function plots the Cross validation indices.\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,8))\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['Class']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1dbaa24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9742470872719279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhammatornriewcharoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9771485727475572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhammatornriewcharoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9766539531100583\n",
      "Score: 0.9762692489475593\n",
      "Score: 0.9777311247650556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhammatornriewcharoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Model 1 : Logistic Model \n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "for train_index, test_index in cv.split(X_res):\n",
    "    # change to loc to define the rows in the dataframe \n",
    "    X_train, X_test, y_train, y_test = X_res.loc[train_index], X_res.loc[test_index], y_res[train_index], y_res[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    #Cross-Validation Prediction Error\n",
    "    score = model.score(X_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5781f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9772365051275569\n",
      "Logistic Model Recall :  0.9687935111720114\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_res, y_res)    \n",
    "score_OOS = model.score(X_test, y_test)\n",
    "print (score_OOS)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Logistic Model Recall : \" , recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d4adbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model Precision :  0.9851890142491122\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Model Precision : \", precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1d072777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha : 0.060000000000000005 0.6871101974673335\n",
      "Alpha : 0.11000000000000001 0.6605438044286925\n",
      "Alpha : 0.16000000000000003 0.6536410838779648\n",
      "Alpha : 0.21000000000000002 0.6442798366140133\n",
      "Alpha : 0.26 0.6320614260441935\n",
      "Alpha : 0.31 0.6203177912573684\n",
      "Alpha : 0.36 0.6145625222833477\n",
      "Alpha : 0.41 0.6077971194414591\n",
      "Alpha : 0.45999999999999996 0.6000217808070734\n",
      "Alpha : 0.51 0.5912374956045621\n",
      "Alpha : 0.56 0.5814424355211354\n",
      "Alpha : 0.6100000000000001 0.5706385495553142\n",
      "Alpha : 0.6600000000000001 0.5588239032962512\n",
      "Alpha : 0.7100000000000002 0.5459993396007043\n",
      "Alpha : 0.7600000000000002 0.5321652700410698\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X_res):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# change to loc to define the rows in the dataframe \u001b[39;00m\n\u001b[1;32m     11\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m X_res\u001b[38;5;241m.\u001b[39mloc[train_index], X_res\u001b[38;5;241m.\u001b[39mloc[test_index], y_res[train_index], y_res[test_index]\n\u001b[0;32m---> 12\u001b[0m     model \u001b[38;5;241m=\u001b[39m lasso\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#Cross-Validation Prediction Error\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1004\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1003\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1004\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath(\n\u001b[1;32m   1005\u001b[0m     X,\n\u001b[1;32m   1006\u001b[0m     y[:, k],\n\u001b[1;32m   1007\u001b[0m     l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_ratio,\n\u001b[1;32m   1008\u001b[0m     eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1009\u001b[0m     n_alphas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1010\u001b[0m     alphas\u001b[38;5;241m=\u001b[39m[alpha],\n\u001b[1;32m   1011\u001b[0m     precompute\u001b[38;5;241m=\u001b[39mprecompute,\n\u001b[1;32m   1012\u001b[0m     Xy\u001b[38;5;241m=\u001b[39mthis_Xy,\n\u001b[1;32m   1013\u001b[0m     copy_X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1014\u001b[0m     coef_init\u001b[38;5;241m=\u001b[39mcoef_[k],\n\u001b[1;32m   1015\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1016\u001b[0m     return_n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1017\u001b[0m     positive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive,\n\u001b[1;32m   1018\u001b[0m     check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;66;03m# from here on **params\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m   1021\u001b[0m     X_offset\u001b[38;5;241m=\u001b[39mX_offset,\n\u001b[1;32m   1022\u001b[0m     X_scale\u001b[38;5;241m=\u001b[39mX_scale,\n\u001b[1;32m   1023\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1024\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[1;32m   1025\u001b[0m     selection\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection,\n\u001b[1;32m   1026\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1027\u001b[0m )\n\u001b[1;32m   1028\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1029\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    617\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    618\u001b[0m         coef_,\n\u001b[1;32m    619\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         positive,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent(\n\u001b[1;32m    632\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    633\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    638\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 2 : LASSO \n",
    "\n",
    "cross_validate_result = {}  \n",
    "# Cross Validate the penalty term in lasso\n",
    "iter_alpha = 0.01\n",
    "for penalty_term in range(100): \n",
    "    accuracies = [] \n",
    "    lasso = linear_model.Lasso(alpha=iter_alpha)\n",
    "    for train_index, test_index in cv.split(X_res):\n",
    "        # change to loc to define the rows in the dataframe \n",
    "        X_train, X_test, y_train, y_test = X_res.loc[train_index], X_res.loc[test_index], y_res[train_index], y_res[test_index]\n",
    "        model = lasso.fit(X_train, y_train)\n",
    "        #Cross-Validation Prediction Error\n",
    "        score = model.score(X_test, y_test)\n",
    "        accuracies.append(score)\n",
    "    cross_validate_result[penalty_term] = (sum(accuracies)/len(accuracies))\n",
    "    iter_alpha += 0.05\n",
    "    print(\"Alpha : \" + str(iter_alpha) + \" \" + str((sum(accuracies)/len(accuracies))))\n",
    "print(cross_validate_result)\n",
    "print(max(cross_validate_result, key=cross_validate_result.get))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c281e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7007530999881367\n",
      "0.6888412900277909\n"
     ]
    }
   ],
   "source": [
    "# Somehow LASSO is performing worst?? \n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_res, y_res)    \n",
    "score_OOS = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(score_OOS)\n",
    "\n",
    "model = linear_model.Lasso(alpha=0.01)\n",
    "model.fit(X_res, y_res)\n",
    "score_OOS = model.score(X_test, y_test)\n",
    "y_pred = model.predict(X_test)\n",
    "print(score_OOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd07a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
