{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e0dc808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# handle dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import warnings\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Data set from https://www.kaggle.com/datasets/yasserh/loan-default-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2915229e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Number of rows :  123628\n"
     ]
    }
   ],
   "source": [
    "# split train test dataset \n",
    "\n",
    "df = pd.read_csv('Loan_Default.csv')\n",
    "# remove some variables that are redundant \n",
    "# year, ID\n",
    "# Interest_rate_spread and rate_of_interest are dropped due to the fact that their values are NA where the loan has defaulted \n",
    "# open credit , secured by, total units : only has one value or too few observations \n",
    "\n",
    "\n",
    "df = df.drop(['year', 'ID', 'Interest_rate_spread', 'rate_of_interest', 'open_credit','Secured_by','total_units'], axis=1)\n",
    "# print(df['Status'].value_counts())\n",
    "# print(df.isna().sum())\n",
    "\n",
    "# Assumption 1 : We assume that upfront charges that are missing are 0 \n",
    "df['Upfront_charges'] = df['Upfront_charges'].fillna(0) \n",
    "# Assumption 2 : We focus on property loans \n",
    "df = df.dropna(subset=[\"property_value\"])\n",
    "# Assumption 3 : drop approv in adv that is NA (only small set of samples)\n",
    "df = df.dropna(subset=[\"approv_in_adv\"])\n",
    "df = df.dropna(subset=[\"term\"])\n",
    "df = df.dropna(subset=[\"income\"])\n",
    "# print(df['Status'].value_counts())\n",
    "\n",
    "# print(df.loc[df['Status'] == 1].head())\n",
    "# print(df.head())\n",
    "print(df[\"LTV\"].isna().sum())\n",
    "# print(df.isna().sum())\n",
    "\n",
    "print(\"Number of rows : \" , len(df.index))\n",
    "# LTV = Loan to Value -> compares the loan value to the value of the asset being purchased as a part of the loan \n",
    "# Property Value \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c15010",
   "metadata": {},
   "source": [
    "# Eyeballing the data\n",
    "\n",
    "So by looking at the data, we see there are two main types of loans : property loan and non-property loan. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b3145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y variables as dataframe \n",
    "y = df['Class']\n",
    "X = df.iloc[:, df.columns != 'Class']\n",
    "X_train, X_OOS_test, y_train, y_OOS_test = train_test_split(X, y, test_size=0.20, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2d7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# solve error by downgrading to install scikit-learn==1.2.2 \n",
    "# ''' steps : \n",
    "# 1. install pip \n",
    "# 2. uninstall sci-kit \n",
    "# 3. uninstall imblearn\n",
    "# 4. install sci-kit 1.2.2 \n",
    "# 5. install imblearn \n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a528c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over sample using SMOTE\n",
    "# -- by inspecting the data, we see that the minority class is extremely class (fraud \"Class\" == 1)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27f4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Code to Inspect the data set -- \n",
    "# df_oversampled = X_smote\n",
    "# df_oversampled['Outcome_Variable'] = y_smote\n",
    "# df_oversampled\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "# df_oversampled['Outcome_Variable'].value_counts().plot(kind='bar', ax=ax, fontsize=14)\n",
    "# ax.set_title('Oversampled Dataset', fontsize=16)\n",
    "# ax.set_ylabel('Observation counts', fontsize=14)\n",
    "# ax.set_xlabel('Class', fontsize=14)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5baf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up K-Fold Cross Validation \n",
    "n_splits = 5\n",
    "shuffle = True\n",
    "random_state = 809\n",
    "cv = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "# plot = plot_cv_indices(cv, X_smote, y_smote, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2991280a",
   "metadata": {},
   "source": [
    "## Model 1 : Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb0ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, n_splits, lw=10):\n",
    "    '''\n",
    "    This function plots the Cross validation indices.\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (15,8))\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y, marker='_', lw=lw, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['Class']\n",
    "    ax.set(yticks=np.arange(n_splits+1) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1dbaa24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6993962887477183\n",
      "0.6974263330539219\n",
      "0.6990107427000005\n",
      "0.6963348570692975\n",
      "0.6986152673174664\n"
     ]
    }
   ],
   "source": [
    "# Model 1 : Logistic Model \n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "for train_index, test_index in cv.split(X_smote):\n",
    "    # change to loc to define the rows in the dataframe \n",
    "    X_train, X_test, y_train, y_test = X_smote.loc[train_index], X_smote.loc[test_index], y_smote[train_index], y_smote[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    #Cross-Validation Prediction Error\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5781f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Model score : 0.9833397703732313\n",
      "Logistic Model Recall :  0.8631578947368421\n",
      "Logistic Model Precision :  0.08055009823182711\n",
      "1s in the data set  0.998\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', max_iter=300)\n",
    "model.fit(X_smote, y_smote)    \n",
    "score_OOS = model.score(X_OOS_test, y_OOS_test)\n",
    "print (\"Logistic Model score :\" , score_OOS)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Logistic Model Recall : \" , recall_score(y_test, y_pred))\n",
    "print(\"Logistic Model Precision : \", precision_score(y_test,y_pred))\n",
    "print(\"Probability if you only predict 0s \", 1-round(95/56867,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c02911",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model 2 : Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d072777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2 : LASSO \n",
    "\n",
    "# Cross Validate the penalty term in lasso\n",
    "cross_validate_result = {}  \n",
    "iter_alpha = 0.01\n",
    "for penalty_term in range(100): \n",
    "    print(penalty_term)\n",
    "    accuracies = [] \n",
    "    lasso = linear_model.Lasso(alpha=iter_alpha)\n",
    "    for train_index, test_index in cv.split(X_smote):\n",
    "        # change to loc to define the rows in the dataframe \n",
    "        X_train, X_test, y_train, y_test = X_smote.loc[train_index], X_smote.loc[test_index], y_smote[train_index], y_smote[test_index]\n",
    "        model = lasso.fit(X_train, y_train)\n",
    "        #Cross-Validation Prediction Error\n",
    "        score = model.score(X_test, y_test)\n",
    "        accuracies.append(score)\n",
    "    cross_validate_result[penalty_term] = (sum(accuracies)/len(accuracies))\n",
    "    iter_alpha += 0.05\n",
    "    print(\"Alpha : \" + str(iter_alpha) + \" \" + str((sum(accuracies)/len(accuracies))))\n",
    "print(cross_validate_result)\n",
    "print(max(cross_validate_result, key=cross_validate_result.get))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6354c645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Model Recall :  0.8740848548998853\n",
      "OLS Model Precision :  0.9868791236150878\n",
      "--\n",
      "LASSO score : \n",
      "LASSO Model Recall :  0.7958013583840522\n",
      "LASSO Model Precision :  0.9852571802992246\n",
      "--\n",
      "Ridge Model Recall :  0.8740848548998853\n",
      "Ridge Model Precision :  0.9868791236150878\n"
     ]
    }
   ],
   "source": [
    "# Somehow LASSO is performing worse?\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(X_smote, y_smote)    \n",
    "y_pred = ols.predict(X_test)\n",
    "# turn the continous value into classification via simple >= 0.5 is 1 \n",
    "y_pred_classification = [1 if x >= 0.5 else 0 for x in y_pred]\n",
    "print(\"OLS Model Recall : \" , recall_score(y_test, y_pred_classification))\n",
    "print(\"OLS Model Precision : \", precision_score(y_test,y_pred_classification))\n",
    "print(\"--\")\n",
    "\n",
    "# LASSO \n",
    "lasso = linear_model.Lasso(alpha=1)\n",
    "lasso.fit(X_smote, y_smote)\n",
    "y_pred = lasso.predict(X_test)\n",
    "# turn the continous value into classification via simple >= 0.5 is 1 \n",
    "y_pred_classification = [1 if x >= 0.5 else 0 for x in y_pred]\n",
    "print(\"LASSO score : \" , )\n",
    "print(\"LASSO Model Recall : \" , recall_score(y_test, y_pred_classification))\n",
    "print(\"LASSO Model Precision : \", precision_score(y_test,y_pred_classification))\n",
    "print(\"--\")\n",
    "\n",
    "# RIDGE\n",
    "ridge = linear_model.Ridge(alpha=1)\n",
    "ridge.fit(X_smote, y_smote)\n",
    "y_pred = ridge.predict(X_test)\n",
    "# turn the continous value into classification via simple >= 0.5 is 1 \n",
    "y_pred_classification = [1 if x >= 0.5 else 0 for x in y_pred]\n",
    "print(\"Ridge Model Recall : \" , recall_score(y_test, y_pred_classification))\n",
    "print(\"Ridge Model Precision : \", precision_score(y_test,y_pred_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47996542",
   "metadata": {},
   "source": [
    "Looks like the curse of dimensionality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289dfa79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
